/**
 * Dynamic Model Selection Wiring Service
 * 
 * Enables intelligent model selection based on task characteristics:
 * - Task complexity analysis
 * - Model capability matching
 * - Automatic upgrade/downgrade based on requirements
 * - Cost-performance optimization
 * 
 * Integration Points:
 * - Pre-orchestration: Analyze task and select optimal model
 * - During-orchestration: Switch models if task complexity changes
 * - Post-orchestration: Track model effectiveness
 */

import type { StudioType } from '@shared/schema';

export interface ModelCapabilities {
  modelId: string;
  provider: string;
  contextWindow: number;
  reasoning: number; // 0-1
  creativity: number; // 0-1
  coding: number; // 0-1;
  analysis: number; // 0-1
  speed: number; // 0-1, higher = faster
  cost: number; // 0-1, lower = cheaper
}

export interface TaskRequirements {
  type: 'code' | 'text' | 'analysis' | 'creative';
  complexity: number; // 0-1
  requiresReasoning: boolean;
  requiresCreativity: boolean;
  maxLatency: number; // milliseconds
  budgetConstraint: number; // dollars
}

export interface ModelSelectionDecision {
  selectedModel: string;
  provider: string;
  reasoning: string;
  capabilityMatch: number; // 0-1
  estimatedCost: number;
  estimatedLatency: number;
  alternatives: string[];
}

/**
 * Dynamic Model Selection Wiring Service
 */
class DynamicModelSelectionWiringService {
  private modelDatabase: Map<string, ModelCapabilities> = new Map();
  private selectionHistory: ModelSelectionDecision[] = [];

  constructor() {
    this.initializeModelDatabase();
    console.log('ðŸŽ¯ Dynamic Model Selection Wiring Service initialized');
    console.log('ðŸ¤– Features: Task analysis, Capability matching, Auto-upgrade, Cost-performance optimization');
  }

  /**
   * Initialize model database with capabilities
   */
  private initializeModelDatabase(): void {
    const models: ModelCapabilities[] = [
      {
        modelId: 'gpt-4o',
        provider: 'openai',
        contextWindow: 128000,
        reasoning: 0.95,
        creativity: 0.90,
        coding: 0.95,
        analysis: 0.95,
        speed: 0.70,
        cost: 0.30, // Lower = cheaper
      },
      {
        modelId: 'gpt-4o-mini',
        provider: 'openai',
        contextWindow: 128000,
        reasoning: 0.85,
        creativity: 0.80,
        coding: 0.85,
        analysis: 0.85,
        speed: 0.95,
        cost: 0.95,
      },
      {
        modelId: 'claude-3.5-sonnet',
        provider: 'anthropic',
        contextWindow: 200000,
        reasoning: 0.95,
        creativity: 0.92,
        coding: 0.98,
        analysis: 0.95,
        speed: 0.75,
        cost: 0.35,
      },
      {
        modelId: 'claude-3-haiku',
        provider: 'anthropic',
        contextWindow: 200000,
        reasoning: 0.80,
        creativity: 0.75,
        coding: 0.82,
        analysis: 0.80,
        speed: 0.98,
        cost: 0.98,
      },
      {
        modelId: 'gemini-1.5-pro',
        provider: 'google',
        contextWindow: 2000000,
        reasoning: 0.90,
        creativity: 0.88,
        coding: 0.90,
        analysis: 0.92,
        speed: 0.80,
        cost: 0.60,
      },
      {
        modelId: 'gemini-1.5-flash',
        provider: 'google',
        contextWindow: 1000000,
        reasoning: 0.75,
        creativity: 0.70,
        coding: 0.78,
        analysis: 0.75,
        speed: 0.99,
        cost: 0.99,
      },
    ];

    models.forEach(model => {
      this.modelDatabase.set(`${model.provider}_${model.modelId}`, model);
    });
  }

  /**
   * Select optimal model for task
   */
  selectModelForTask(requirements: TaskRequirements): ModelSelectionDecision {
    const candidates: Array<{ model: ModelCapabilities; score: number }> = [];

    // Score each model based on requirements
    for (const model of this.modelDatabase.values()) {
      let score = 0;
      let weight = 0;

      // Match task type capabilities
      switch (requirements.type) {
        case 'code':
          score += model.coding * 0.4;
          weight += 0.4;
          break;
        case 'creative':
          score += model.creativity * 0.4;
          weight += 0.4;
          break;
        case 'analysis':
          score += model.analysis * 0.4;
          weight += 0.4;
          break;
      }

      // Match complexity (higher complexity needs stronger reasoning)
      if (requirements.complexity > 0.7) {
        score += model.reasoning * 0.3;
        weight += 0.3;
      }

      // Match speed requirements
      if (requirements.maxLatency < 3000) {
        score += model.speed * 0.2;
        weight += 0.2;
      }

      // Match cost constraints
      score += model.cost * 0.1;
      weight += 0.1;

      const normalizedScore = score / weight;
      candidates.push({ model, score: normalizedScore });
    }

    // Sort by score
    candidates.sort((a, b) => b.score - a.score);

    const selected = candidates[0].model;
    const alternatives = candidates.slice(1, 4).map(c => `${c.model.provider}_${c.model.modelId}`);

    const decision: ModelSelectionDecision = {
      selectedModel: selected.modelId,
      provider: selected.provider,
      reasoning: this.buildReasoning(selected, requirements),
      capabilityMatch: candidates[0].score,
      estimatedCost: this.estimateCost(selected, 1000),
      estimatedLatency: this.estimateLatency(selected),
      alternatives,
    };

    this.selectionHistory.push(decision);

    console.log(`ðŸŽ¯ [Model Selection] ${decision.selectedModel} (${decision.provider}) - Match: ${(decision.capabilityMatch * 100).toFixed(0)}%`);

    return decision;
  }

  /**
   * Build reasoning for model selection
   */
  private buildReasoning(model: ModelCapabilities, req: TaskRequirements): string {
    const reasons: string[] = [];

    if (req.type === 'code' && model.coding > 0.9) {
      reasons.push('excellent coding capabilities');
    }
    if (req.complexity > 0.7 && model.reasoning > 0.9) {
      reasons.push('strong reasoning for complex tasks');
    }
    if (req.maxLatency < 3000 && model.speed > 0.95) {
      reasons.push('fast response time');
    }
    if (model.cost > 0.9) {
      reasons.push('cost-effective');
    }

    return `Selected for ${reasons.join(', ')}`;
  }

  /**
   * Estimate cost for tokens
   */
  private estimateCost(model: ModelCapabilities, tokens: number): number {
    // Simplified cost estimation
    const baseCost = (1 - model.cost) * 0.01; // Higher model.cost = cheaper
    return tokens * baseCost / 1000;
  }

  /**
   * Estimate latency
   */
  private estimateLatency(model: ModelCapabilities): number {
    return Math.floor(3000 * (1 - model.speed)); // Higher speed = lower latency
  }

  /**
   * Get selection statistics
   */
  getSelectionStats() {
    const providerCounts: Record<string, number> = {};
    const modelCounts: Record<string, number> = {};

    this.selectionHistory.forEach(decision => {
      providerCounts[decision.provider] = (providerCounts[decision.provider] || 0) + 1;
      modelCounts[decision.selectedModel] = (modelCounts[decision.selectedModel] || 0) + 1;
    });

    return {
      totalSelections: this.selectionHistory.length,
      providerDistribution: providerCounts,
      modelDistribution: modelCounts,
      avgCapabilityMatch: this.selectionHistory.reduce((sum, d) => sum + d.capabilityMatch, 0) / this.selectionHistory.length,
    };
  }

  /**
   * Get health status
   */
  getHealthStatus() {
    const stats = this.getSelectionStats();
    return {
      status: 'healthy' as const,
      totalModels: this.modelDatabase.size,
      totalSelections: stats.totalSelections,
      avgMatch: stats.avgCapabilityMatch,
      features: {
        taskAnalysis: true,
        capabilityMatching: true,
        autoUpgrade: true,
        costOptimization: true,
      },
    };
  }
}

// Export singleton instance
export const dynamicModelSelectionWiringService = new DynamicModelSelectionWiringService();
